# Masked Image Modeling: A Survey
We surveyed recent studies on masked image modeling (MIM), an approach that emerged as a powerful self-supervised learning technique in computer vision. The MIM task involves masking some information, e.g. pixels, patches, or even latent representations, and training a model, usually an autoencoder, to predicting the missing information by using the context available in the visible part of the input. This repository categorizes the papers about masked image modeling, according to their contribution. The classifcation is based on our survey [Masked Image Modeling: A Survey](https://arxiv.org/abs/2408.06687).

## Summary

#### Single Level Contribution
1. [Masking Strategy](#1)
2. [Downstream Task](#2)
3. [Target Features](#3)
4. [Objective Function](#4)
5. [Model Architecture](#5)
6. [Theoretical Analysis](#6) 
___ 
#### Two Level Contribution
7. [Target Features and Objective Function](#7)
8. [Model Architecture and Objective Function](#8)
9. [Masking Strategy and Target Features](#9)
10. [Objective Function and Theoretical Analysis](#10)
11. [Downstream Task and Theoretical Analysis](#11)
12. [Masking Strategy and Objective Function](#12)
13. [Masking Strategy and Downstream Task](#13)
14. [Masking Strategy and Model Architecture](#14)
15. [Target Features and Downstream Task](#15)
16. [Model Architecture and Target Features](#16)
___ 
#### Multi-Level Contribution
17. [Masking Strategy, Model Architecture and Objective Function](#17)
18. [Masking Strategy, Target Features and Objective Function](#18)
19. [Masking Strategy, Model Architecture, Downstream Task and Objective Function](#19)

## Content

### Masking Strategy <a name="1"></a>
  1. [MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://papers.nips.cc/paper_files/paper/2022/file/944618542d80a63bbec16dfbd2bd689a-Paper-Conference.pdf)
  2. [Masked image training for generalizable deep image denoising](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Masked_Image_Training_for_Generalizable_Deep_Image_Denoising_CVPR_2023_paper.pdf)
  3. [Masked images are counterfactual samples for robust fine-tuning](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_Masked_Images_Are_Counterfactual_Samples_for_Robust_Fine-Tuning_CVPR_2023_paper.pdf)
  4. [Hard patches mining for masked image modeling](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Hard_Patches_Mining_for_Masked_Image_Modeling_CVPR_2023_paper.pdf)
  5. [What to hide from your students: Attention-guided masked image modeling](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136900299.pdf)
  6. [SMAUG: Sparse Masked Autoencoder for Efficient Video-Language Pre-training](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.pdf)
  7. [SemMAE: Semantic-Guided Masking for Learning Masked Autoencoders](https://proceedings.neurips.cc/paper_files/paper/2022/file/5c186016d0844767209dc36e9e61441b-Paper-Conference.pdf9)
  8. [MedIM: Boost Medical Image Representation via Radiology Report-guided Masking](https://link.springer.com/chapter/10.1007/978-3-031-43907-0_2)
  9. [autoSMIM: Automatic Superpixel-Based Masked Image Modeling for Skin Lesion Segmentation](https://pubmed.ncbi.nlm.nih.gov/37379178/)
  10. [Self-supervised learning with masked image modeling for teeth numbering, detection of dental restorations, and instance segmentation in dental panoramic radiographs](https://openaccess.thecvf.com/content/WACV2023/papers/Almalki_Self-Supervised_Learning_With_Masked_Image_Modeling_for_Teeth_Numbering_Detection_WACV_2023_paper.pdf)
  11. [Yet Another Traffic Classifier: A Masked Autoencoder Based Traffic Transformer with Multi-Level Flow Representation](https://ojs.aaai.org/index.php/AAAI/article/view/25674/25446)
  12. [VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_VideoMAE_V2_Scaling_Video_Masked_Autoencoders_With_Dual_Masking_CVPR_2023_paper.pdf)
  13. [MRM: Masked Relation Modeling for Medical Image Pre-Training with Genetics](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.pdf)
  14. [MA2CL: Masked attentive contrastive learning for multi-agent reinforcement learning](https://www.ijcai.org/proceedings/2023/0470.pdf)
  15. [Learning audio-visual speech representation by masked multimodal cluster prediction](https://openreview.net/pdf?id=Z1Qlm11uOM)
  16. [OmniMAE: Single Model Masked Pretraining on Images and Videos](https://openaccess.thecvf.com/content/CVPR2023/papers/Girdhar_OmniMAE_Single_Model_Masked_Pretraining_on_Images_and_Videos_CVPR_2023_paper.pdf)
  17. [Good helper is around you: Attention-driven masked image modeling](https://ojs.aaai.org/index.php/AAAI/article/view/25269/25041)
  18. [MM-3DScene: 3D Scene Understanding by Customizing Masked Modeling with Informative-Preserved Reconstruction and Self-Distilled Consistency](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_MM-3DScene_3D_Scene_Understanding_by_Customizing_Masked_Modeling_With_Informative-Preserved_CVPR_2023_paper.pdf)
  19. [Masked autoencoders for point cloud self-supervised learning](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136620591.pdf)
  20. [Masked generative adversarial networks are data-efficient generation learners](https://proceedings.neurips.cc/paper_files/paper/2022/file/0efcb1885b8534109f95ca82a5319d25-Paper-Conference.pdf)
  21. [SimMIM: A Simple Framework for Masked Image Modeling](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_SimMIM_A_Simple_Framework_for_Masked_Image_Modeling_CVPR_2022_paper.pdf)
  22. [Masked autoencoders are scalable vision learners](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf)
  23. [DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_DropMAE_Masked_Autoencoders_With_Spatial-Attention_Dropout_for_Tracking_Tasks_CVPR_2023_paper.pdf)
  24. [MGMAE: Motion Guided Masking for Video Masked Autoencoding](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.pdf)
  25. [Multi-modal masked pre-training for monocular panoramic depth completion](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610372.pdf)
  26. [Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training](https://arxiv.org/pdf/2209.07098)
  27. [Masked generative distillation](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710053.pdf)
  28. [Masked motion predictors are strong 3D action representation learners](https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf)
  29. [Siamese masked autoencoders](https://proceedings.neurips.cc/paper_files/paper/2023/file/7ffb9f1b57628932518505b532301603-Paper-Conference.pdf)
  30. [MixMAE: Mixed and Masked Autoencoder for Efficient Pretraining of Hierarchical Vision Transformers](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_MixMAE_Mixed_and_Masked_Autoencoder_for_Efficient_Pretraining_of_Hierarchical_CVPR_2023_paper.pdf)
  31. [Masked frequency modeling for self-supervised visual pre-training](https://openreview.net/pdf?id=9-umxtNPx5E)
### Downstream Task <a name="2"></a>
  1. [MaskGIT: Masked Generative Image Transformer]()
  2. [MAESTER: Masked Autoencoder Guided Segmentation at Pixel Resolution for Accurate, Self-Supervised Subcellular Structure Recognition]()
  3. [GeoMIM: Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding]()
  4. [AMAE: Adaptation of Pre-Trained Masked Autoencoder for Dual-Distribution Anomaly Detection in Chest X-Rays]()
  5. [Delving into masked autoencoders for multi-label thorax disease classification]()
  6. [Seeing beyond the brain: Conditional diffusion model with sparse masked modeling for vision decoding]()
  7. [Test-Time Training with Masked Autoencoders]()
  8. [Masked Image Modeling Advances 3D Medical Image Analysis]()
  9. [Graph Masked Autoencoder Enhanced Predictor for Neural Architecture Search]()
  10. [MAGVIT: Masked Generative Video Transformer]()
  11. [Advancing Radiograph Representation Learning with Masked Record Modeling]()
  12. [Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations]()
  13. [Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology]()
  14. [Unleashing vanilla vision transformer with masked image modeling for object detection]()
### Target Features <a name="3"></a>
  1. [Masked motion encoding for self-supervised video representation learning]()
  2. [MIMT: Masked Image Modeling Transformer for Video Compression]()
  3. [RILS: Masked Visual Reconstruction in Language Semantic Space]()
  4. [SdAE: Self-distillated Masked Autoencoder]()
  5. [Masked Autoencoders Enable Efficient Knowledge Distillers]()
  6. [Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors]()
  7. [EVA: Exploring the Limits of Masked Visual Representation Learning at Scale]()
  8. [MeshMAE: Masked Autoencoders for 3D Mesh Data Analysis]()
  9. [GeoMAE: Masked Geometric Target Prediction for Self-supervised Point Cloud Pre-Training]()
  10. [Masked Siamese networks for label-efficient learning]()
  11. [Point cloud domain adaptation via masked local 3D structure prediction]()
  12. [An empirical study of end-to-end video-language transformers with masked visual modeling]()
  13. [Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision Transformers]()
### Objective Function <a name="4"></a>
  1. [MATE: Masked Autoencoders are Online 3D Test-Time Learners]()
  2. [MIMEx: Intrinsic Rewards from Masked Input Modeling]()
  3. [Exploring the role of mean teachers in self-supervised masked auto-encoders]()
  4. [Masked autoencoding does not help natural language supervision at scale]()
  5. [Masked Discrimination for Self-Supervised Learning on Point Clouds]()
  6. [Masked Frequency Consistency for Domain-Adaptive Semantic Segmentation of Laparoscopic Images]()
  7. [Masked unsupervised self-training for label-free image classification]()
  8. [Contrastive masked autoencoders are stronger vision learners]()
### Model Architecture <a name="5"></a>
  1. [MCMAE: Masked Convolution Meets Masked Autoencoders]()
  2. [Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling]()
  3. [Task-Customized Masked Autoencoder via Mixture of Cluster-Conditional Experts]()
  4. [Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection]()
  5. [SparseMAE: Sparse Training Meets Masked Autoencoders]()
  6. [Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection]()
  7. [RevColV2: Exploring disentangled representations in masked image modeling]()
### Theoretical Analysis <a name="6"></a>
  1. [Towards Understanding Why Mask Reconstruction Pretraining Helps in Downstream Tasks]()
  2. [Rethinking Out-of-distribution (OOD) Detection: Masked Image Modeling is All You Need]()
  3. [Understanding Masked Autoencoders via Hierarchical Latent Variable Models]()
  4. [Masked prediction: A parameter identifiability view]()
  5. [On masked pre-training and the marginal likelihood]()
  6. [On Data Scaling in Masked Image Modeling]()
  7. [Revealing the dark secrets of masked image modeling]()
  8. [Improving Adversarial Robustness of Masked Autoencoders via Test-time Frequency-domain Prompting]()
### Target Features and Objective Function <a name="7"></a>
  1. [Self-supervised visual representations learning by contrastive mask prediction]()
  2. [Masked contrastive representation learning for reinforcement learning]()
  3. [Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked Auto-Encoder]()
  4. [MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining]()
  5. [Generic-to-specific distillation of masked autoencoders]()
  6. [Understanding masked image modeling via learning occlusion invariant feature]()
  7. [Contrastive Masked Image-Text Modeling for Medical Visual Representation Learning]()
  8. [Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning]()
  9. [Masked image modeling with local multi-scale reconstruction]()
### Model Architecture and Objective Function <a name="8"></a>
  1. [SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners]()
  2. [Masked auto-encoders meet generative adversarial networks and beyond]()
  3. [Stare at What You See: Masked Image Modeling without Reconstruction]()
  4. [CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders]()
  5. [SwinMM: Masked Multi-view with Swin Transformers for 3D Medical Image Segmentation]()
  6. [Contrastive audio-visual masked autoencoder]()
  7. [VideoMAC: Video Masked Autoencoders Meet ConvNets]()
### Masking Strategy and Target Features <a name="9"></a>
  1. [Masked retraining teacher-student framework for domain adaptive object detection]()
  2. [Mx2M: masked cross-modality modeling in domain adaptation for 3D semantic segmentation]()
  3. [Diffusion models as masked autoencoders]()
  4. [Representation learning for visual object tracking by masked appearance transfer]()
  5. [Joint-MAE: 2D-3D joint masked autoencoders for 3D point cloud pre-training]()
  6. [Learning 3D representations from 2D pre-trained models via image-to-point masked autoencoders]()
  7. [Compact transformer tracker with correlative masked modeling]()
  8. [Masked Embedding Modeling With Rapid Domain Adjustment for Few-Shot Image Classification]()
  9. [Supervised masked knowledge distillation for few-shot transformers]()
### Objective Function and Theoretical Analysis <a name="10"></a>
  1. [How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders]()
###  Downstream Task and Theoretical Analysis <a name="11"></a>
  1. [MaskSketch: Unpaired Structure-guided Masked Image Generation]()
### Masking Strategy and Objective Function <a name="12"></a>
  1. [Masked Scene Contrast: A Scalable Framework for Unsupervised 3D Representation Learning]()
  2. [Contextual image masking modeling via synergized contrasting without view augmentation for faster and better visual pretraining]()
  3. [HAP: Structure-Aware Masked Image Modeling for Human-Centric Perception]()
  4. [MST: Masked Self-Supervised Transformer for Visual Representation]()
  5. [MAST: Masked Augmentation Subspace Training for Generalizable Self-Supervised Priors]()
  6. [Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling]()
  7. [Contrastive masked autoencoders for self-supervised video hashing]()
  8. [Masked image modeling with denoising contrast]()
  9. [{Denoising Masked AutoEncoders Help Robust Classification]()
### Masking Strategy and Downstream Task <a name="13"></a>
  1. [Masked Autoencoders As Spatiotemporal Learners]()
  2. [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training]()
  3. [Tell me what happened: Unifying text-guided video completion via multimodal masked video generation]()
  4. [Masked Spatio-Temporal Structure Prediction for Self-Supervised Learning on Point Cloud Videos]()
  5. [Global k-Space Interpolation for Dynamic MRI Reconstruction Using Masked Image Modeling]()
  6. [FocusMAE: Gallbladder Cancer Detection from Ultrasound Videos with Focused Masked Autoencoders]()
  7. [SMAE: Few-shot Learning for HDR Deghosting with Saturation-Aware Masked Autoencoders]()
  8. [LEMaRT: Label-Efficient Masked Region Transform for Image Harmonization]()
  9. [MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis]()
  10. [MARLIN: Masked Autoencoder for facial video Representation LearnINg]()
  11. [Multiple instance learning framework with masked hard instance mining for whole slide image classification]()
  12. [PMatch: Paired Masked Image Modeling for Dense Geometric Matching]()
  13. [Masked Autoencoders are Efficient Class Incremental Learners]()
### Masking Strategy and Model Architecture <a name="14"></a>
  1. [Green hierarchical vision transformer for masked image modeling]()
  2. [CL-MAE: Curriculum-Learned Masked Autoencoders]()
  3. [ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders]()
  4. [4M: Massively Multimodal Masked Modeling]()
  5. [Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis]()
  6. [Unmasked Teacher: Towards Training-Efficient Video Foundation Models]()
  7. [PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection]()
  8. [Scale-MAE: A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning]()
  9. [MultiMAE: Multi-modal Multi-task Masked Autoencoders]()
  10. [Multi-view masked world models for visual robotic manipulation]()
### Target Features and Downstream Task <a name="15"></a>
  1. [MAGVLT: Masked Generative Vision-and-Language Transformer]()
  2. [Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification]()
  3. [Deblurring masked autoencoder is better recipe for ultrasound image recognition]()
  4. [Masked Video Distillation: Rethinking Masked Feature Modeling for Self-Supervised Video Representation Learning]()
  5. [T4P: Test-Time Training of Trajectory Prediction via Masked Autoencoder and Actor-Specific Token Memory]()
  6. [MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling]()
### Model Architecture and Target Features <a name="16"></a>
  1. [Masked Autoencoders Are Stronger Knowledge Distillers]()
  2. [Bootstrapped Masked Autoencoders for Vision BERT Pretraining]()
  3. [Cycle-consistent masked autoencoder for unsupervised domain generalization]()
  4. [Self-supervised Pre-training with Masked Shape Prediction for 3D Scene Understanding]()
  5. [Masked feature prediction for self-supervised visual pre-training]()
  6. [Masked Image Residual Learning for Scaling Deeper Vision Transformers]()
  7. [Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)]()
### Masking Strategy, Model Architecture and Objective Function <a name="17"></a>
  1. [AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders]()
  2. [StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training]()
  3. [MaskViT: Masked Visual Pre-Training for Video Prediction]()
  4. [Masked AutoDecoder is Effective Multi-Task Vision Generalist]()
  5. [Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning]()
### Masking Strategy, Target Features and Objective Function <a name="18"></a>
  1. [One-for-All: Proposal Masked Cross-Class Anomaly Detection]()
  2. [Masked vision and language modeling for multi-modal representation learning]()
  3. [Architecture-Agnostic Masked Image Modeling--From ViT back to CNN]()
  4. [Masked Feature Generation Network for Few-Shot Learning]()
### Masking Strategy, Model Architecture, Downstream Task and Objective Function <a name="19"></a>
  1. [MAViL: Masked Audio-Video Learners]()
  2. [Improved masked image generation with token-critic]()
  3. [Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly Detectors]()
  4. [Audiovisual masked autoencoders]()
